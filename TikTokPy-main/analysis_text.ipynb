{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "import csv\n",
    "from pandas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './videos/'\n",
    "path2 = './audio/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video file to Audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(path1):\n",
    "    print(filename)\n",
    "    if (filename.endswith(\".mp4\")): #or .avi, .mpeg, whatever.\n",
    "        id = os.path.splitext(filename)[0]\n",
    "        os.system(\"ffmpeg -i {0} {1}.wav\".format(os.path.join(path1,filename), os.path.join(path2,id)))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio file to Text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run following command for whisper access\n",
    "# ! pip install git+https://github.com/openai/whisper.git soundfile\n",
    "r = sr.Recognizer()\n",
    "header = ['ID', 'Transcription']\n",
    "f = open('transcriptions.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(header)\n",
    "\n",
    "for filename in os.listdir(path2):\n",
    "    if (filename.endswith(\".wav\")): #or .avi, .mpeg, whatever.\n",
    "        audio = sr.AudioFile(os.path.join(path2,filename))\n",
    "        with audio as source:\n",
    "            audio = r.record(source)                  \n",
    "            result = r.recognize_whisper(audio)\n",
    "            data = [os.path.splitext(filename)[0], result]\n",
    "            writer.writerow(data)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying BERT sentiment analysis to extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-25 14:06:59.684437: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" I'm not gonna tell you who Baby baby baby baby So round you, I love you I'm not gonna tell you who Baby baby I'm shay Cause baby baby So round you, baby I love you, do it, but I'm dead\", \" There's a new foundation in town, so we're gonna try it. In case you haven't heard, Charlotte Tilbury made Hollywood flawless filter in a foundation form. This is called Charlotte's Beautiful Skin Foundation. Since they're supposedly so similar, we're gonna compare them side by side. Starting off with flawless filter and shade three on the side of my face, we just blended it in, stunning. Now onto Charlotte's beautiful skin. I got shade six, so I hope it matches. Alright blending it in, let's see. You're kidding. Look how stunning. Okay so comparing the two, obviously the foundation has more coverage than the flawless filter, but they both have that really similar radiance, which is Shutskiss. Let's try applying some foundation over the flawless filter. Technically flawless filter is just a primer. This side is a little bit more radiant than this side. What do we think you guys?\", '', \" Who could do it to believe it? I've been a hater, sexy nut.\", ' Oh', ' haft torture', \" Did you know that shallow at filberry has a perfect meal? Sex and up. It's sadly a crime scene Their are not qualified to stay ...block them up\", \" This and this. They're the same thing. DOOPS! DOOPS!\", \" Take a little sin, privacy, I'm a dog, I'ma make this shit worth I ain't of em, I ain't of em I ain't of em, I ain't of em, I ain't of em With a body, with a body, with a body, with a body She comes to our heart, to the tiny, deep My last thing about me, I'm cooling my money Last night, you're gonna be the only thing I need So hard to let my mind, like, you know what I'm doing?\", \" Trying the makeup revolution concealer to see if it's a tease for the Charlotte Tilbury contour wand. I apply my bronzer first. Charlotte Tilbury contour wand in the shade medium dark. Make up revolution eye-pricing concealer in the shade Deep Caramel. I'm shook. They are super similar and when you apply your blush over the top you really can't tell.\"]\n"
     ]
    }
   ],
   "source": [
    "# data = read_csv(\"transcriptions.csv\")\n",
    "# pred_sentences = data['Transcription'].tolist()\n",
    "f = open('transcriptions.csv', 'r')\n",
    "file = csv.DictReader(f)\n",
    "ids = []\n",
    "pred_sentences = []\n",
    "for col in file:\n",
    "    ids.append(col['ID'])\n",
    "    pred_sentences.append(col['Transcription'])\n",
    "print (pred_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7152274500090858794 : \n",
      " Negative\n",
      "7054746897738698031 : \n",
      " Negative\n",
      "7115762593788071174 : \n",
      " Negative\n",
      "7086798266838322437 : \n",
      " Negative\n",
      "7081298765352537350 : \n",
      " Negative\n",
      "7123195527327698222 : \n",
      " Negative\n",
      "7099531036937260330 : \n",
      " Negative\n",
      "7145293556553551150 : \n",
      " Negative\n",
      "7046066693180919086 : \n",
      " Negative\n",
      "7017540145020751106 : \n",
      " Negative\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf_batch = tokenizer(pred_sentences, max_length=512, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "labels = ['Negative','Positive']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(pred_sentences)):\n",
    "    print(ids[i], \": \\n\", labels[label[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
